{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JYHYL/EART60702-Group3/blob/Stacking/1-data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "60c40888-2dad-4d08-8dcf-16a18eebb700",
      "metadata": {
        "id": "60c40888-2dad-4d08-8dcf-16a18eebb700"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7847c2d-98f5-406b-a858-819ca73aed2b",
      "metadata": {
        "id": "e7847c2d-98f5-406b-a858-819ca73aed2b"
      },
      "source": [
        "**Methodology**\n",
        "\n",
        "Since both Random Forest and LSTM models utilize a sliding window approach for prediction, the effective lengths of the training and testing predictions are shorter than the original input periods. Therefore, the period from April 1, 2006 to December 31, 2040 is defined as the new training set, and April 1, 2050 to November 30, 2080 as the new testing set. Corresponding data are extracted from the LSTM_prediction and RF_prediction results.\n",
        "\n",
        "\n",
        "As Model 85 is based on monthly-scale data, its prediction outputs are linearly interpolated to match the daily resolution. The new datasets are stored in the DataSet directory in Excel format with the following file names: stacking_data_model_train_<model_id> and stacking_data_model_test_<model_id>.\n",
        "\n",
        "\n",
        "Each dataset includes the following featuresï¼š\n",
        "\n",
        "a. LSTM predictions based on the original model (LSTM_day)\n",
        "\n",
        "b. RF predictions based on the original model (RF_day)\n",
        "\n",
        "c. LSTM predictions based on Model 85 (LSTM_85)\n",
        "\n",
        "d. RF predictions based on Model 85 (RF_85)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f8dabe-e813-4f14-ab56-798509d1c9b5",
      "metadata": {
        "id": "46f8dabe-e813-4f14-ab56-798509d1c9b5"
      },
      "source": [
        "Extracting Training Data for Each Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3ca96a5f-1a10-40aa-ba4d-31e16c5bb033",
      "metadata": {
        "id": "3ca96a5f-1a10-40aa-ba4d-31e16c5bb033"
      },
      "outputs": [],
      "source": [
        "# ---------------- Configuration ----------------\n",
        "day_models = [3, 4, 5, 6, 7, 8]         # Daily models (MME)\n",
        "month_model = 85                        # Monthly model (CHESS)\n",
        "start_date = '2006-04-01'\n",
        "end_date = '2040-12-31'\n",
        "\n",
        "# GitHub raw base URLs (different branches for LSTM and RF)\n",
        "base_url_lstm = 'https://raw.githubusercontent.com/JYHYL/EART60702-Group3/LSTM_prediction'\n",
        "base_url_rf = 'https://raw.githubusercontent.com/JYHYL/EART60702-Group3/RF'\n",
        "\n",
        "# Directory structure in GitHub (relative to branches)\n",
        "lstm_dir_day = 'LSTM_MME_prediction'\n",
        "rf_dir_day = 'RF_MME/RF_MME_prediction'\n",
        "lstm_dir_month = 'LSTM_CHESS_prediction'\n",
        "rf_dir_month = 'RF_CHESS/RF_CHESS_predictions'\n",
        "\n",
        "# ---------------- Step 1: Collect common dates shared by all day models ----------------\n",
        "date_sets = []\n",
        "\n",
        "for model_id in day_models:\n",
        "    file_url = f'{base_url_lstm}/{lstm_dir_day}/model_{model_id}_train_predictions.csv'\n",
        "    df = pd.read_csv(file_url, parse_dates=['date'])\n",
        "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
        "    date_sets.append(set(df['date']))\n",
        "\n",
        "# Intersect all date sets to get common prediction dates\n",
        "common_dates = sorted(set.intersection(*date_sets))\n",
        "df_full_dates = pd.DataFrame({'date': common_dates})\n",
        "\n",
        "# ---------------- Step 2: Interpolate monthly LSTM predictions from Model 85 ----------------\n",
        "file_lstm_85 = f'{base_url_lstm}/{lstm_dir_month}/model_85_train_predictions.csv'\n",
        "df_lstm_85_raw = pd.read_csv(file_lstm_85, parse_dates=['date'])\n",
        "df_lstm_85_raw = df_lstm_85_raw[(df_lstm_85_raw['date'] >= start_date) & (df_lstm_85_raw['date'] <= end_date)]\n",
        "\n",
        "df_lstm_85_interp = df_lstm_85_raw.set_index('date').reindex(df_full_dates['date'])\n",
        "df_lstm_85_interp['Predicted'] = df_lstm_85_interp['Predicted'].interpolate(method='linear', limit_direction='both')\n",
        "df_lstm_85_interp = df_lstm_85_interp.reset_index().rename(columns={'index': 'date', 'Predicted': 'LSTM_85'})\n",
        "\n",
        "# ---------------- Step 3: Interpolate monthly RF predictions from Model 85 ----------------\n",
        "file_rf_85 = f'{base_url_rf}/{rf_dir_month}/model_85_train_predictions.csv'\n",
        "df_rf_85_raw = pd.read_csv(file_rf_85, parse_dates=['date'])\n",
        "df_rf_85_raw = df_rf_85_raw[(df_rf_85_raw['date'] >= start_date) & (df_rf_85_raw['date'] <= end_date)]\n",
        "\n",
        "df_rf_85_interp = df_rf_85_raw.set_index('date').reindex(df_full_dates['date'])\n",
        "df_rf_85_interp['Predicted'] = df_rf_85_interp['Predicted'].interpolate(method='linear', limit_direction='both')\n",
        "df_rf_85_interp = df_rf_85_interp.reset_index().rename(columns={'index': 'date', 'Predicted': 'RF_85'})\n",
        "\n",
        "# ---------------- Step 4: Create and save stacking datasets ----------------\n",
        "for model_id in day_models:\n",
        "    # Load LSTM predictions for the current model\n",
        "    file_lstm = f'{base_url_lstm}/{lstm_dir_day}/model_{model_id}_train_predictions.csv'\n",
        "    df_lstm = pd.read_csv(file_lstm, parse_dates=['date'])\n",
        "    df_lstm = df_lstm[(df_lstm['date'] >= start_date) & (df_lstm['date'] <= end_date)]\n",
        "    df_lstm = df_lstm[['date', 'Predicted']].rename(columns={'Predicted': 'LSTM_day'})\n",
        "\n",
        "    # Load RF predictions for the current model\n",
        "    file_rf = f'{base_url_rf}/{rf_dir_day}/model_{model_id}_train_predictions.csv'\n",
        "    df_rf = pd.read_csv(file_rf, parse_dates=['date'])\n",
        "    df_rf = df_rf[(df_rf['date'] >= start_date) & (df_rf['date'] <= end_date)]\n",
        "    df_rf = df_rf[['date', 'Predicted']].rename(columns={'Predicted': 'RF_day'})\n",
        "\n",
        "    # Load actual values (reusing LSTM file)\n",
        "    df_actual = pd.read_csv(file_lstm, parse_dates=['date'])\n",
        "    df_actual = df_actual[(df_actual['date'] >= start_date) & (df_actual['date'] <= end_date)]\n",
        "    df_actual = df_actual[['date', 'Actual']]\n",
        "\n",
        "    # Merge all features into a single DataFrame\n",
        "    df_merge = df_full_dates.merge(df_lstm, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_rf, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_lstm_85_interp, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_rf_85_interp, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_actual, on='date', how='left')\n",
        "\n",
        "    # Reorder columns\n",
        "    df_merge = df_merge[['date', 'LSTM_day', 'RF_day', 'LSTM_85', 'RF_85', 'Actual']]\n",
        "\n",
        "    # Save to Excel file\n",
        "    output_name = f'stacking_data_model_train_{model_id}.xlsx'\n",
        "    df_merge.to_excel(output_name, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21665ad8-4c58-4a26-820f-b65310a8b920",
      "metadata": {
        "id": "21665ad8-4c58-4a26-820f-b65310a8b920"
      },
      "source": [
        "Extracting Testing Data for Each Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fc644ecb-f1be-4ebb-890e-0168357c1367",
      "metadata": {
        "id": "fc644ecb-f1be-4ebb-890e-0168357c1367"
      },
      "outputs": [],
      "source": [
        "# ---------------- Configuration ----------------\n",
        "day_models = [3, 4, 5, 6, 7, 8]\n",
        "month_model = 85\n",
        "start_date = '2050-04-01'\n",
        "end_date = '2080-11-30'\n",
        "\n",
        "# GitHub raw base URLs for each branch\n",
        "base_url_lstm = 'https://raw.githubusercontent.com/JYHYL/EART60702-Group3/LSTM_prediction'\n",
        "base_url_rf = 'https://raw.githubusercontent.com/JYHYL/EART60702-Group3/RF'\n",
        "\n",
        "lstm_dir_day = 'LSTM_MME_prediction'\n",
        "rf_dir_day = 'RF_MME/RF_MME_prediction'\n",
        "lstm_dir_month = 'LSTM_CHESS_prediction'\n",
        "rf_dir_month = 'RF_CHESS/RF_CHESS_predictions'\n",
        "\n",
        "# ---------------- Step 1: Collect common dates shared across all models ----------------\n",
        "date_sets = []\n",
        "\n",
        "for model_id in day_models:\n",
        "    file_url = f'{base_url_lstm}/{lstm_dir_day}/model_{model_id}_test_predictions.csv'\n",
        "    df = pd.read_csv(file_url, parse_dates=['date'])\n",
        "    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
        "    date_sets.append(set(df['date']))\n",
        "\n",
        "common_dates = sorted(set.intersection(*date_sets))\n",
        "df_full_dates = pd.DataFrame({'date': common_dates})\n",
        "\n",
        "# ---------------- Step 2: Interpolate monthly LSTM predictions (Model 85) ----------------\n",
        "file_lstm_85 = f'{base_url_lstm}/{lstm_dir_month}/model_85_test_predictions.csv'\n",
        "df_lstm_85_raw = pd.read_csv(file_lstm_85, parse_dates=['date'])\n",
        "df_lstm_85_raw = df_lstm_85_raw[(df_lstm_85_raw['date'] >= start_date) & (df_lstm_85_raw['date'] <= end_date)]\n",
        "\n",
        "df_lstm_85_interp = df_lstm_85_raw.set_index('date').reindex(df_full_dates['date'])\n",
        "df_lstm_85_interp['Predicted'] = df_lstm_85_interp['Predicted'].interpolate(method='linear', limit_direction='both')\n",
        "df_lstm_85_interp = df_lstm_85_interp.reset_index().rename(columns={'index': 'date', 'Predicted': 'LSTM_85'})\n",
        "\n",
        "# ---------------- Step 3: Interpolate monthly RF predictions (Model 85) ----------------\n",
        "file_rf_85 = f'{base_url_rf}/{rf_dir_month}/model_85_test_predictions.csv'\n",
        "df_rf_85_raw = pd.read_csv(file_rf_85, parse_dates=['date'])\n",
        "df_rf_85_raw = df_rf_85_raw[(df_rf_85_raw['date'] >= start_date) & (df_rf_85_raw['date'] <= end_date)]\n",
        "\n",
        "df_rf_85_interp = df_rf_85_raw.set_index('date').reindex(df_full_dates['date'])\n",
        "df_rf_85_interp['Predicted'] = df_rf_85_interp['Predicted'].interpolate(method='linear', limit_direction='both')\n",
        "df_rf_85_interp = df_rf_85_interp.reset_index().rename(columns={'index': 'date', 'Predicted': 'RF_85'})\n",
        "\n",
        "# ---------------- Step 4: Build and save stacking test datasets ----------------\n",
        "for model_id in day_models:\n",
        "    # Load LSTM predictions for the current model\n",
        "    file_lstm = f'{base_url_lstm}/{lstm_dir_day}/model_{model_id}_test_predictions.csv'\n",
        "    df_lstm = pd.read_csv(file_lstm, parse_dates=['date'])\n",
        "    df_lstm = df_lstm[(df_lstm['date'] >= start_date) & (df_lstm['date'] <= end_date)]\n",
        "    df_lstm = df_lstm[['date', 'Predicted']].rename(columns={'Predicted': 'LSTM_day'})\n",
        "\n",
        "    # Load RF predictions for the current model\n",
        "    file_rf = f'{base_url_rf}/{rf_dir_day}/model_{model_id}_test_predictions.csv'\n",
        "    df_rf = pd.read_csv(file_rf, parse_dates=['date'])\n",
        "    df_rf = df_rf[(df_rf['date'] >= start_date) & (df_rf['date'] <= end_date)]\n",
        "    df_rf = df_rf[['date', 'Predicted']].rename(columns={'Predicted': 'RF_day'})\n",
        "\n",
        "    # Load actual values (from LSTM prediction file)\n",
        "    df_actual = pd.read_csv(file_lstm, parse_dates=['date'])\n",
        "    df_actual = df_actual[(df_actual['date'] >= start_date) & (df_actual['date'] <= end_date)]\n",
        "    df_actual = df_actual[['date', 'Actual']]\n",
        "\n",
        "    # Merge all columns by date\n",
        "    df_merge = df_full_dates.merge(df_lstm, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_rf, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_lstm_85_interp, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_rf_85_interp, on='date', how='left')\n",
        "    df_merge = df_merge.merge(df_actual, on='date', how='left')\n",
        "\n",
        "    # Reorder columns\n",
        "    df_merge = df_merge[['date', 'LSTM_day', 'RF_day', 'LSTM_85', 'RF_85', 'Actual']]\n",
        "\n",
        "    # Save to Excel\n",
        "    output_name = f'stacking_data_model_test_{model_id}.xlsx'\n",
        "    df_merge.to_excel(output_name, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a9b609-50df-419f-98b5-27de68a4aa29",
      "metadata": {
        "id": "40a9b609-50df-419f-98b5-27de68a4aa29"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "study",
      "language": "python",
      "name": "study"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}